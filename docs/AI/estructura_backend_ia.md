# Arquitectura del M√≥dulo de IA (Backend)

**Sistema:** SmartSales365 - M√≥dulo de Predicci√≥n de Ventas  
**Framework:** Django 4.2.7 + scikit-learn  
**Fecha:** Noviembre 2025

---

## üìê Arquitectura General

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React/Next.js)                      ‚îÇ
‚îÇ  - Dashboard de Predicciones                                     ‚îÇ
‚îÇ  - Gr√°ficos interactivos (Recharts)                             ‚îÇ
‚îÇ  - Filtros din√°micos                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTP REST API
                     ‚îÇ /api/ai/dashboard/
                     ‚îÇ /api/ai/train/
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DJANGO BACKEND (Python)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              apps/ai/views.py                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - AIModelViewSet (endpoints REST)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                      ‚îÇ                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           apps/ai/services/                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  DataPreparationService                             ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - get_historical_sales_data()                      ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - prepare_training_data()                          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ModelTrainingService                               ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - train_model()                                    ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - evaluate_model()                                 ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - save_model()                                     ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  PredictionService                                  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - load_model()                                     ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - predict_next_n_months()                          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - get_dashboard_data()                             ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ SQL Queries
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    POSTGRESQL DATABASE                           ‚îÇ
‚îÇ  - orders_pedido                                                 ‚îÇ
‚îÇ  - orders_detallepedido                                         ‚îÇ
‚îÇ  - products_prenda                                              ‚îÇ
‚îÇ  - products_categoria                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FILE SYSTEM                                   ‚îÇ
‚îÇ  models/                                                         ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ ventas_model_v1.0_20251111.pkl  (Modelo entrenado)        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ ventas_model_v1.0_20251111_metadata.json (Metadata)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 1. Capa de Servicios (Service Layer)

### 1.1. DataPreparationService

**Ubicaci√≥n:** `apps/ai/services/data_preparation.py`

**Responsabilidad:** Preparar y transformar datos crudos para el modelo de ML

#### M√©todos Principales:

##### `get_historical_sales_data(months_back=36)`

**Prop√≥sito:** Extraer datos hist√≥ricos de ventas desde PostgreSQL

**Input:**
```python
months_back: int = 36  # N√∫mero de meses hacia atr√°s
```

**Proceso:**
```python
1. Calcular fecha de inicio (hoy - months_back)
2. Query a base de datos:
   SELECT a√±o, mes, categoria, SUM(cantidad), COUNT(DISTINCT pedido)
   FROM orders_detallepedido
   WHERE created_at >= fecha_inicio
   GROUP BY a√±o, mes, categoria
3. Retornar DataFrame de pandas
```

**Output:**
```python
DataFrame con columnas:
- a√±o: int (2023, 2024, 2025)
- mes: int (1-12)
- categoria: str ('Blusas', 'Vestidos', 'Jeans', 'Jackets')
- cantidad_vendida: int
- num_transacciones: int
- precio_promedio: float
```

**Casos especiales manejados:**
```python
# 1. Meses sin ventas (se completan con 0)
if not existe_venta(2025, 2, 'Jackets'):
    agregar_fila(a√±o=2025, mes=2, categoria='Jackets', cantidad=0)

# 2. Categor√≠as nuevas (se ignoran si tienen <3 meses de datos)
if categoria.meses_con_datos < 3:
    excluir_categoria()

# 3. Datos futuros (se filtran)
if fecha > datetime.now():
    excluir_registro()
```

---

##### `prepare_training_data(df, target_column='cantidad_vendida')`

**Prop√≥sito:** Aplicar feature engineering y preparar X, y para entrenamiento

**Input:**
```python
df: DataFrame (resultado de get_historical_sales_data)
target_column: str = 'cantidad_vendida'
```

**Proceso:**

**Paso 1: Eliminar features no predictivas**
```python
# ‚ùå Eliminar: num_transacciones, precio_promedio
# Raz√≥n: No conocemos estos valores en el futuro
df = df.drop(['num_transacciones', 'precio_promedio'], axis=1)
```

**Paso 2: One-Hot Encoding de categor√≠as**
```python
# Convertir 'Blusas', 'Vestidos', etc. en columnas binarias
df_encoded = pd.get_dummies(df, columns=['categoria'], prefix='cat')

Antes:
| a√±o | mes | categoria |
|-----|-----|-----------|
| 2025| 1   | Blusas    |

Despu√©s:
| a√±o | mes | cat_Blusas | cat_Vestidos | cat_Jeans | cat_Jackets |
|-----|-----|------------|--------------|-----------|-------------|
| 2025| 1   | 1          | 0            | 0         | 0           |
```

**Paso 3: Feature engineering temporal**
```python
import numpy as np

# Componentes trigonom√©tricas (capturan ciclicidad)
df['mes_sin'] = np.sin(2 * np.pi * df['mes'] / 12)
df['mes_cos'] = np.cos(2 * np.pi * df['mes'] / 12)

# Trimestre
df['trimestre'] = (df['mes'] - 1) // 3 + 1  # 1, 2, 3, 4
```

**Output:**
```python
X: DataFrame con features
   [a√±o, mes, mes_sin, mes_cos, trimestre, cat_Blusas, cat_Vestidos, cat_Jeans, cat_Jackets]

y: Series con target
   [cantidad_vendida]
```

---

### 1.2. ModelTrainingService

**Ubicaci√≥n:** `apps/ai/services/model_training.py`

**Responsabilidad:** Entrenar, evaluar y persistir el modelo de ML

#### M√©todos Principales:

##### `train_model(months_back=36, test_size=0.2)`

**Prop√≥sito:** Entrenar modelo Random Forest con datos hist√≥ricos

**Input:**
```python
months_back: int = 36  # Meses de hist√≥rico
test_size: float = 0.2  # Porcentaje para testing (20%)
```

**Proceso:**

**Paso 1: Obtener y preparar datos**
```python
# Usar DataPreparationService
data_service = DataPreparationService()
df = data_service.get_historical_sales_data(months_back)
X, y = data_service.prepare_training_data(df)
```

**Paso 2: Divisi√≥n Train/Test**
```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=test_size,  # 20%
    random_state=42
)

# Ejemplo:
# Total: 140 registros
# Train: 112 registros (80%)
# Test: 28 registros (20%)
```

**Paso 3: Entrenar Random Forest**
```python
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(
    n_estimators=100,      # 100 √°rboles
    max_depth=10,          # Profundidad m√°xima
    min_samples_split=5,   # M√≠nimo para dividir
    min_samples_leaf=2,    # M√≠nimo en hojas
    random_state=42
)

model.fit(X_train, y_train)
```

**Paso 4: Evaluar modelo**
```python
y_pred = model.predict(X_test)

metrics = {
    'r2_score': r2_score(y_test, y_pred),
    'mae': mean_absolute_error(y_test, y_pred),
    'rmse': np.sqrt(mean_squared_error(y_test, y_pred))
}
```

**Paso 5: Analizar importancia de features**
```python
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)
```

**Output:**
```python
{
    'model': RandomForestRegressor (entrenado),
    'metrics': {
        'r2_score': 0.9727,
        'mae': 10.34,
        'rmse': 15.82
    },
    'feature_importance': DataFrame,
    'feature_names': ['a√±o', 'mes', ...]
}
```

---

##### `save_model(model, metadata, filename=None)`

**Prop√≥sito:** Persistir modelo y metadata en disco

**Input:**
```python
model: RandomForestRegressor (entrenado)
metadata: dict {
    'version': 'v1.0',
    'trained_at': '2025-11-11 15:04:56',
    'r2_score': 0.9727,
    'mae': 10.34,
    'feature_names': ['a√±o', 'mes', ...],
    'categories': ['Blusas', 'Vestidos', 'Jeans', 'Jackets']
}
filename: str (opcional)
```

**Proceso:**
```python
import joblib
import json
from datetime import datetime

# 1. Generar nombre de archivo
if not filename:
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    version = metadata.get('version', 'v1.0')
    filename = f'ventas_model_{version}_{timestamp}'

# 2. Guardar modelo (.pkl)
model_path = f'models/{filename}.pkl'
joblib.dump(model, model_path)

# 3. Guardar metadata (.json)
metadata_path = f'models/{filename}_metadata.json'
with open(metadata_path, 'w') as f:
    json.dump(metadata, f, indent=2)
```

**Estructura del archivo metadata.json:**
```json
{
  "version": "v1.0",
  "trained_at": "2025-11-11T15:04:56",
  "model_type": "RandomForestRegressor",
  "hyperparameters": {
    "n_estimators": 100,
    "max_depth": 10,
    "min_samples_split": 5,
    "min_samples_leaf": 2
  },
  "metrics": {
    "r2_score": 0.9727,
    "mae": 10.34,
    "rmse": 15.82
  },
  "feature_names": [
    "a√±o", "mes", "mes_sin", "mes_cos", "trimestre",
    "cat_Blusas", "cat_Vestidos", "cat_Jeans", "cat_Jackets"
  ],
  "categories": ["Blusas", "Vestidos", "Jeans", "Jackets"],
  "training_data": {
    "months_back": 36,
    "total_records": 140,
    "date_range": "2023-01-01 to 2025-11-11"
  }
}
```

---

### 1.3. PredictionService

**Ubicaci√≥n:** `apps/ai/services/prediction.py`

**Responsabilidad:** Cargar modelo y generar predicciones para el frontend

#### M√©todos Principales:

##### `load_model(model_path=None)`

**Prop√≥sito:** Cargar modelo entrenado desde disco

**Input:**
```python
model_path: str (opcional)
# Si no se proporciona, carga el modelo m√°s reciente
```

**Proceso:**
```python
import joblib
import json
from pathlib import Path

# 1. Determinar path del modelo
if not model_path:
    models_dir = Path('models/')
    model_files = sorted(models_dir.glob('ventas_model_*.pkl'))
    model_path = model_files[-1]  # M√°s reciente

# 2. Cargar modelo
model = joblib.load(model_path)

# 3. Cargar metadata
metadata_path = model_path.with_suffix('').with_suffix('.json')  # .pkl ‚Üí .json
with open(metadata_path, 'r') as f:
    metadata = json.load(f)

# 4. Validar integridad
assert model is not None, "Modelo no pudo cargarse"
assert metadata['model_type'] == 'RandomForestRegressor'
```

**Output:**
```python
{
    'model': RandomForestRegressor (cargado),
    'metadata': dict (metadata del modelo)
}
```

---

##### `predict_next_n_months(n_months=3, categories=None)`

**Prop√≥sito:** Generar predicciones para los pr√≥ximos N meses

**Input:**
```python
n_months: int = 3  # N√∫mero de meses a predecir
categories: list = None  # Si None, predice todas las categor√≠as
```

**Proceso:**

**Paso 1: Determinar per√≠odo de predicci√≥n**
```python
from datetime import datetime
from dateutil.relativedelta import relativedelta

hoy = datetime.now()
primer_mes_futuro = hoy + relativedelta(months=1)

periodos = [
    primer_mes_futuro + relativedelta(months=i)
    for i in range(n_months)
]

# Ejemplo (hoy = 11-Nov-2025):
# periodos = [Dic 2025, Ene 2026, Feb 2026]
```

**Paso 2: Preparar features de entrada**
```python
import pandas as pd
import numpy as np

categorias = categories or ['Blusas', 'Vestidos', 'Jeans', 'Jackets']

features_input = []
for periodo in periodos:
    a√±o = periodo.year
    mes = periodo.month
    
    for categoria in categorias:
        # Crear feature vector
        row = {
            'a√±o': a√±o,
            'mes': mes,
            'mes_sin': np.sin(2 * np.pi * mes / 12),
            'mes_cos': np.cos(2 * np.pi * mes / 12),
            'trimestre': (mes - 1) // 3 + 1,
            'cat_Blusas': 1 if categoria == 'Blusas' else 0,
            'cat_Vestidos': 1 if categoria == 'Vestidos' else 0,
            'cat_Jeans': 1 if categoria == 'Jeans' else 0,
            'cat_Jackets': 1 if categoria == 'Jackets' else 0
        }
        features_input.append(row)

X_future = pd.DataFrame(features_input)
```

**Paso 3: Predecir**
```python
model = self.load_model()['model']
predictions = model.predict(X_future)

# predictions = [638.2, 149.1, 298.4, 143.2, 175.3, ...]
```

**Paso 4: Formatear resultados**
```python
results = []
idx = 0
for periodo in periodos:
    for categoria in categorias:
        results.append({
            'a√±o': periodo.year,
            'mes': periodo.month,
            'periodo': periodo.strftime('%b %Y'),  # 'Dic 2025'
            'categoria': categoria,
            'cantidad_predicha': round(predictions[idx]),
            'confianza': 'Alta' if metadata['r2_score'] > 0.90 else 'Media'
        })
        idx += 1
```

**Output:**
```python
[
    {
        'a√±o': 2025,
        'mes': 12,
        'periodo': 'Dic 2025',
        'categoria': 'Blusas',
        'cantidad_predicha': 638,
        'confianza': 'Alta'
    },
    {
        'a√±o': 2025,
        'mes': 12,
        'periodo': 'Dic 2025',
        'categoria': 'Vestidos',
        'cantidad_predicha': 149,
        'confianza': 'Alta'
    },
    # ... (12 registros para 3 meses √ó 4 categor√≠as)
]
```

---

##### `get_dashboard_data(historic_months=12, prediction_months=3)`

**Prop√≥sito:** Generar todo el data payload para el dashboard frontend

**Input:**
```python
historic_months: int = 12  # Meses hist√≥ricos a incluir
prediction_months: int = 3  # Meses a predecir
```

**Proceso:**

**Paso 1: Datos hist√≥ricos**
```python
data_service = DataPreparationService()
df_historical = data_service.get_historical_sales_data(historic_months)

# Agregar a nivel mensual (sumar todas las categor√≠as)
historical_totals = df_historical.groupby(['a√±o', 'mes']).agg({
    'cantidad_vendida': 'sum'
}).reset_index()
```

**Paso 2: Predicciones**
```python
predictions = self.predict_next_n_months(prediction_months)
```

**Paso 3: Calcular m√©tricas clave**
```python
total_predicho = sum(p['cantidad_predicha'] for p in predictions)
promedio_mensual = total_predicho / prediction_months

ultimo_historico = historical_totals.iloc[-1]['cantidad_vendida']
primer_predicho = sum(
    p['cantidad_predicha'] 
    for p in predictions 
    if p['mes'] == predictions[0]['mes']
)
tendencia = ((primer_predicho - ultimo_historico) / ultimo_historico) * 100
```

**Output (JSON para frontend):**
```python
{
    "model_info": {
        "version": "v1.0_20251111_150456",
        "trained_at": "2025-11-11T15:04:56",
        "r2_score": 0.9727,
        "mae": 10.34
    },
    "key_metrics": {
        "total_predicted": 2199,
        "average_monthly": 733,
        "trend_percentage": -10.3,
        "confidence": "Alta"
    },
    "historical_data": [
        {"period": "Nov 2024", "total": 1267},
        {"period": "Dic 2024", "total": 1254},
        {"period": "Ene 2025", "total": 425},
        # ... 12 meses
    ],
    "predictions": [
        {
            "a√±o": 2025,
            "mes": 12,
            "periodo": "Dic 2025",
            "categoria": "Blusas",
            "cantidad_predicha": 638,
            "confianza": "Alta"
        },
        # ... todas las predicciones
    ],
    "predictions_by_category": {
        "Blusas": [
            {"periodo": "Dic 2025", "cantidad": 638},
            {"periodo": "Ene 2026", "cantidad": 175},
            {"periodo": "Feb 2026", "cantidad": 263}
        ],
        "Vestidos": [...],
        "Jeans": [...],
        "Jackets": [...]
    }
}
```

---

## 2. Capa de Vistas (Views / Controllers)

**Ubicaci√≥n:** `apps/ai/views.py`

### AIModelViewSet

**Responsabilidad:** Exponer endpoints REST para el frontend

#### Endpoints:

##### `GET /api/ai/dashboard/`

**Query Parameters:**
```
?historic_months=12
&prediction_months=3
```

**Respuesta:**
```json
{
    "model_info": {...},
    "key_metrics": {...},
    "historical_data": [...],
    "predictions": [...]
}
```

##### `POST /api/ai/train/`

**Body:**
```json
{
    "months_back": 36,
    "test_size": 0.2
}
```

**Respuesta:**
```json
{
    "success": true,
    "model_version": "v1.0_20251111_150456",
    "metrics": {
        "r2_score": 0.9727,
        "mae": 10.34,
        "rmse": 15.82
    },
    "message": "Modelo entrenado exitosamente"
}
```

---

## 3. Flujo de Trabajo Completo

### Flujo 1: Entrenamiento Inicial

```
1. Usuario ejecuta: python manage.py train_model --months 36
   ‚Üì
2. ModelTrainingService.train_model(months_back=36)
   ‚Üì
3. DataPreparationService.get_historical_sales_data(36)
   - Query a PostgreSQL
   - Agregar a nivel A√±o-Mes-Categor√≠a
   ‚Üì
4. DataPreparationService.prepare_training_data(df)
   - Feature engineering
   - One-Hot Encoding
   - Componentes trigonom√©tricas
   ‚Üì
5. RandomForestRegressor.fit(X_train, y_train)
   - Entrenar 100 √°rboles
   - Evaluar en test set
   ‚Üì
6. ModelTrainingService.save_model()
   - Guardar ventas_model_v1.0_20251111.pkl
   - Guardar metadata.json
   ‚Üì
7. ‚úÖ Modelo listo para predicciones
```

### Flujo 2: Predicci√≥n en Tiempo Real (Dashboard)

```
1. Frontend hace: GET /api/ai/dashboard/?prediction_months=3
   ‚Üì
2. AIModelViewSet.dashboard_view()
   ‚Üì
3. PredictionService.get_dashboard_data(prediction_months=3)
   ‚Üì
4. PredictionService.load_model()
   - Cargar ventas_model_v1.0_20251111.pkl
   ‚Üì
5. PredictionService.predict_next_n_months(3)
   - Preparar features para Dic, Ene, Feb
   - model.predict(X_future)
   ‚Üì
6. Formatear JSON response
   ‚Üì
7. ‚Üê Retornar al frontend
   ‚Üì
8. Frontend renderiza dashboard con Recharts
```

---

## 4. Gesti√≥n de Modelos (Model Versioning)

### Estructura de Archivos:

```
models/
‚îú‚îÄ‚îÄ ventas_model_v1.0_20251111_150456.pkl
‚îú‚îÄ‚îÄ ventas_model_v1.0_20251111_150456_metadata.json
‚îú‚îÄ‚îÄ ventas_model_v1.1_20260115_103022.pkl
‚îú‚îÄ‚îÄ ventas_model_v1.1_20260115_103022_metadata.json
‚îî‚îÄ‚îÄ ...
```

### Estrategia de Versionado:

**Versi√≥n Sem√°ntica:**
```
v[MAJOR].[MINOR]_[TIMESTAMP]

MAJOR: Cambio de algoritmo (ej. Random Forest ‚Üí XGBoost)
MINOR: Cambio de features o hiperpar√°metros
TIMESTAMP: Fecha/hora del entrenamiento
```

**Ejemplo:**
```
v1.0_20251111_150456 ‚Üí Primera versi√≥n, Random Forest, 11-Nov-2025 15:04
v1.1_20260115_103022 ‚Üí Misma arquitectura, features mejoradas, 15-Ene-2026
v2.0_20260301_140000 ‚Üí Cambio a XGBoost, 1-Mar-2026
```

### Rollback de Modelo:

Si un modelo nuevo tiene mal rendimiento:
```python
# 1. Identificar modelo anterior
model_path = 'models/ventas_model_v1.0_20251111_150456.pkl'

# 2. Cambiar variable de entorno o config
settings.ACTIVE_MODEL_PATH = model_path

# 3. PredictionService cargar√° el modelo especificado
```

---

## 5. Escalabilidad y Mejoras Futuras

### Optimizaciones Actuales:

1. **Caching de modelo:**
   ```python
   # El modelo se carga una vez y se mantiene en memoria
   _cached_model = None
   
   def load_model():
       global _cached_model
       if _cached_model is None:
           _cached_model = joblib.load('models/...')
       return _cached_model
   ```

2. **Predicciones batch:**
   ```python
   # Predecir 3 meses √ó 4 categor√≠as = 12 predicciones en una sola llamada
   predictions = model.predict(X_future)  # X_future tiene 12 filas
   ```

### Mejoras Futuras:

1. **Predicciones en tiempo real con Celery:**
   ```python
   @shared_task
   def async_train_model(months_back):
       service = ModelTrainingService()
       service.train_model(months_back)
   ```

2. **A/B Testing de modelos:**
   ```python
   # Comparar modelo antiguo vs nuevo
   predictions_v1 = model_v1.predict(X)
   predictions_v2 = model_v2.predict(X)
   # Elegir el de menor MAE en datos recientes
   ```

3. **Monitoreo de drift:**
   ```python
   # Detectar si el modelo est√° perdiendo precisi√≥n
   if mae_actual > mae_entrenamiento * 1.5:
       send_alert("Modelo necesita reentrenamiento")
   ```

---

## 6. Seguridad y Validaci√≥n

### Validaciones Implementadas:

1. **Validaci√≥n de inputs:**
   ```python
   if months_back < 12 or months_back > 60:
       raise ValueError("months_back debe estar entre 12 y 60")
   
   if prediction_months < 1 or prediction_months > 12:
       raise ValueError("prediction_months debe estar entre 1 y 12")
   ```

2. **Validaci√≥n de datos:**
   ```python
   # Detectar anomal√≠as en datos hist√≥ricos
   if cantidad_vendida < 0:
       raise ValueError("Cantidad no puede ser negativa")
   
   if cantidad_vendida > 10000:
       logger.warning(f"Cantidad inusualmente alta: {cantidad_vendida}")
   ```

3. **Control de acceso:**
   ```python
   # Solo usuarios autenticados pueden acceder a endpoints de IA
   permission_classes = [IsAuthenticated, HasAIPermission]
   ```

---

## 7. Testing

### Tests Implementados:

```python
# tests/test_data_preparation.py
def test_get_historical_sales_data():
    service = DataPreparationService()
    df = service.get_historical_sales_data(months_back=12)
    assert df.shape[0] > 0
    assert 'cantidad_vendida' in df.columns

# tests/test_model_training.py
def test_train_model():
    service = ModelTrainingService()
    result = service.train_model(months_back=36)
    assert result['metrics']['r2_score'] > 0.80

# tests/test_prediction.py
def test_predict_next_n_months():
    service = PredictionService()
    predictions = service.predict_next_n_months(n_months=3)
    assert len(predictions) == 12  # 3 meses √ó 4 categor√≠as
```

---

## 8. Conclusi√≥n

La arquitectura del m√≥dulo de IA est√° dise√±ada para:

‚úÖ **Separaci√≥n de responsabilidades** (Service Layer Pattern)  
‚úÖ **F√°cil mantenimiento** (cada servicio tiene una funci√≥n clara)  
‚úÖ **Escalabilidad** (f√°cil agregar nuevas categor√≠as o features)  
‚úÖ **Testeable** (cada servicio puede ser testeado independientemente)  
‚úÖ **Versionado robusto** (modelos con timestamp y metadata)  

**La arquitectura soporta el crecimiento del sistema y facilita futuras mejoras.**

---

**√öltima actualizaci√≥n:** 11 de Noviembre de 2025  
**Versi√≥n:** 1.0  
**Pr√≥xima revisi√≥n:** Enero 2026
